{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PYTHON NOTEBOOK FOR DATA PREPROCESSING ANALYSIS OF MODELS USED FOR THE RECOMMENDATION SYSTEM PRESENT IN PHASE 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['city'] = df_cleaned['city'].str.lower()\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['us_state'] = df_cleaned['us_state'].str.lower()\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['city'] = df_cleaned['city'].str.capitalize()\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['us_state'] = df_cleaned['us_state'].str.capitalize()\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['working_hours'] = df_cleaned['working_hours'].astype(str)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['working_hours'] = df_cleaned['working_hours'].apply(lambda x: re.sub(r'[a-zA-Z\\s]+', '', x))\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['working_hours'] = df_cleaned['working_hours'].fillna('Unknown')\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1126356153.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['name'] = df_cleaned['name'].str.title()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cleaned = df.dropna(subset=['latitude', 'popular_times', 'longitude', 'rating'])\n",
    "\n",
    "df_cleaned['city'] = df_cleaned['city'].str.lower()\n",
    "df_cleaned['us_state'] = df_cleaned['us_state'].str.lower()\n",
    "df_cleaned['city'] = df_cleaned['city'].str.capitalize()\n",
    "df_cleaned['us_state'] = df_cleaned['us_state'].str.capitalize()\n",
    "\n",
    "df_cleaned['working_hours'] = df_cleaned['working_hours'].astype(str)\n",
    "df_cleaned['working_hours'] = df_cleaned['working_hours'].apply(lambda x: re.sub(r'[a-zA-Z\\s]+', '', x))\n",
    "df_cleaned['working_hours'] = df_cleaned['working_hours'].fillna('Unknown')\n",
    "\n",
    "df_cleaned['name'] = df_cleaned['name'].str.title()\n",
    "\n",
    "df_cleaned = df_cleaned[(df_cleaned['latitude'].between(-90, 90)) & (df_cleaned['longitude'].between(-180, 180))]\n",
    "df_cleaned['latitude'] = df_cleaned['latitude'].round(6)\n",
    "df_cleaned['longitude'] = df_cleaned['longitude'].round(6)\n",
    "\n",
    "df_cleaned['rating_category'] = pd.cut(df_cleaned['rating'], bins=[0, 3, 4.5, 5], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "df_cleaned['name'] = df_cleaned['name'].str.strip()\n",
    "df_cleaned['city'] = df_cleaned['city'].str.strip()\n",
    "\n",
    "def has_values_after_colon(working_hours):\n",
    "    try:\n",
    "\n",
    "        parts = working_hours.split(':')\n",
    "        if len(parts) > 6 and parts[6].strip():  \n",
    "            return True  \n",
    "        if len(parts) > 7 and parts[7].strip():  \n",
    "            return True  \n",
    "        return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "df_cleaned['rating'] = pd.to_numeric(df_cleaned['rating'], errors='coerce')\n",
    "df_cleaned = df_cleaned.dropna(subset=['rating'])\n",
    "\n",
    "df_cleaned['rating_scaled'] = (df_cleaned['rating'] / df_cleaned['rating'].max()) * 5\n",
    "df_cleaned['popular_times'] = df_cleaned['popular_times'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "df_cleaned = df_cleaned[df_cleaned['popular_times'].apply(lambda x: isinstance(x, list) and len(x) == 7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2369 entries, 0 to 3996\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   name             2369 non-null   object  \n",
      " 1   popular_times    2369 non-null   object  \n",
      " 2   latitude         2369 non-null   float64 \n",
      " 3   longitude        2369 non-null   float64 \n",
      " 4   working_hours    2369 non-null   object  \n",
      " 5   city             2368 non-null   object  \n",
      " 6   us_state         2368 non-null   object  \n",
      " 7   rating           2369 non-null   float64 \n",
      " 8   rating_category  2369 non-null   category\n",
      " 9   rating_scaled    2369 non-null   float64 \n",
      "dtypes: category(1), float64(4), object(5)\n",
      "memory usage: 187.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Places with hourly data: 2369\n",
      "Percentage of hourly data available: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\1196743762.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_hourly = df_cleaned.copy()\n",
    "\n",
    "def safe_eval(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return eval(x)\n",
    "        except:\n",
    "            return None\n",
    "    return x\n",
    "\n",
    "df_hourly['popular_times'] = df_hourly['popular_times'].apply(safe_eval)\n",
    "\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "for day_idx, day in enumerate(days):\n",
    "    for hour in range(24):\n",
    "        df_hourly[f'{day}_{hour:02d}'] = df_hourly['popular_times'].apply(\n",
    "            lambda x: x[(day_idx + 1) % 7][hour] if isinstance(x, list) and len(x) == 7 and len(x[(day_idx - 1) % 7]) == 24 else np.nan\n",
    "        )\n",
    "\n",
    "df_hourly = df_hourly.drop('popular_times', axis=1)\n",
    "\n",
    "hourly_data_count = df_hourly.iloc[:, -168:].notna().sum().sum()\n",
    "total_possible = len(df_hourly) * 168 \n",
    "\n",
    "print(f\"Places with hourly data: {hourly_data_count / 168:.0f}\")\n",
    "print(f\"Percentage of hourly data available: {hourly_data_count / total_possible:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Working Hours from Popular Times Data using Random Forest by Keshav Narayan Srinivasan UBIT: 50610509\n",
    "- *Analysis:* Random Forest was used to predict the working hours of tourist spots based on features extracted from popular_times. The model handles high-dimensional data well and can capture complex relationships between popular time trends and working hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\2577886321.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['parsed_hours'] = data['working_hours'].fillna(\"\").apply(robust_parse_working_hours)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\2577886321.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['popular_hours'] = data.apply(lambda row: aggregate_popular_times(row, days_of_week), axis=1)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\2577886321.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['parsed_features'] = data['parsed_hours'].apply(hours_to_features)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\2577886321.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['popular_features'] = data['popular_hours'].apply(hours_to_features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1663503539427912\n",
      "Predicted working hours: [(np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(0.0))]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data = df_hourly\n",
    "\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def robust_parse_working_hours(working_hours):\n",
    "    parsed_hours = []\n",
    "    try:\n",
    "        for day in working_hours.split(\":\")[1:]:\n",
    "            if '-' in day:\n",
    "                times = day.split('-')\n",
    "                if len(times) >= 2:\n",
    "                    open_time, close_time = times[:2]\n",
    "                    open_hour = float(open_time.split(\":\")[0]) + (float(open_time.split(\":\")[1]) / 60 if \":\" in open_time else 0)\n",
    "                    close_hour = float(close_time.split(\":\")[0]) + (float(close_time.split(\":\")[1]) / 60 if \":\" in close_time else 0)\n",
    "                    parsed_hours.append((open_hour, close_hour))\n",
    "                else:\n",
    "                    parsed_hours.append((None, None))\n",
    "            else:\n",
    "                parsed_hours.append((None, None))\n",
    "    except Exception:\n",
    "        parsed_hours = [(None, None)] * 7\n",
    "    return parsed_hours\n",
    "\n",
    "data['parsed_hours'] = data['working_hours'].fillna(\"\").apply(robust_parse_working_hours)\n",
    "\n",
    "def aggregate_popular_times(row, days):\n",
    "    daily_hours = []\n",
    "    for day in days:\n",
    "        hours = [i for i in range(24) if row.get(f\"{day}_{i:02}\", 0) > 0]\n",
    "        if hours:\n",
    "            daily_hours.append((hours[0], hours[-1] + 1))\n",
    "        else:\n",
    "            daily_hours.append((None, None))\n",
    "    return daily_hours\n",
    "\n",
    "data['popular_hours'] = data.apply(lambda row: aggregate_popular_times(row, days_of_week), axis=1)\n",
    "\n",
    "def hours_to_features(hours):\n",
    "    return [item for sublist in hours for item in sublist]\n",
    "\n",
    "data['parsed_features'] = data['parsed_hours'].apply(hours_to_features)\n",
    "data['popular_features'] = data['popular_hours'].apply(hours_to_features)\n",
    "\n",
    "def normalize_features(features, target_length=14, placeholder=0):\n",
    "    if len(features) < target_length:\n",
    "        features.extend([placeholder] * (target_length - len(features)))\n",
    "    elif len(features) > target_length:\n",
    "        features = features[:target_length]\n",
    "    return features\n",
    "\n",
    "data['parsed_features'] = data['parsed_features'].apply(lambda x: normalize_features(x, 14, placeholder=0))\n",
    "data['popular_features'] = data['popular_features'].apply(lambda x: normalize_features(x, 14, placeholder=0))\n",
    "\n",
    "data = data.dropna(subset=['parsed_features', 'popular_features'])\n",
    "\n",
    "data['parsed_features'] = data['parsed_features'].apply(lambda x: [0 if v is None else v for v in x])\n",
    "data['popular_features'] = data['popular_features'].apply(lambda x: [0 if v is None else v for v in x])\n",
    "\n",
    "X = np.array(data['popular_features'].tolist())\n",
    "y = np.array(data['parsed_features'].tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.nan_to_num(y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "def features_to_hours(features):\n",
    "    return [(round(features[i], 2), round(features[i + 1], 2)) for i in range(0, len(features), 2)]\n",
    "\n",
    "sample_prediction = features_to_hours(y_pred[0])\n",
    "print(f\"Predicted working hours: {sample_prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATING A NEW working_hours DATA USING POPULAR TIMES DATA AS THE OLD working_hours DID NOT CORRELATE WELL WITH THE popular_times DATA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('working_hours', inplace=True, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features_to_working_hours(features):\n",
    "    \"\"\"\n",
    "    Convert features (list of open/close times) to the working hours string format.\n",
    "    Example: [(0, 24), (0, 24), (0, 24), (0, 24), (0, 24), (0, 0), (0, 0)] -> \":24:24:24:24:24::\"\n",
    "    \"\"\"\n",
    "    hours = []\n",
    "    for i in range(0, len(features), 2):\n",
    "        open_hour = features[i]\n",
    "        close_hour = features[i + 1]\n",
    "        if open_hour is not None and close_hour is not None:\n",
    "            if open_hour == 0 and close_hour == 0:\n",
    "                # Closed day\n",
    "                hours.append(\"\")\n",
    "            elif open_hour == 0 and close_hour == 24:\n",
    "                # 24-hour open\n",
    "                hours.append(\"24\")\n",
    "            else:\n",
    "                # Format to \"open-close\"\n",
    "                hours.append(f\"{int(open_hour)}-{int(close_hour)}\")\n",
    "        else:\n",
    "            hours.append(\"\")\n",
    "    return \":\" + \":\".join(hours)\n",
    "\n",
    "data['calculated_working_hours'] = data['popular_features'].apply(features_to_working_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekday_hours(working_hours):\n",
    "    try:\n",
    "        parts = working_hours.split(':')\n",
    "        weekday_parts = parts[1:6]\n",
    "        weekday_hours = sum(1 for part in weekday_parts if part.strip())\n",
    "        return weekday_hours\n",
    "    except Exception as e:\n",
    "        return 0 \n",
    "def get_weekend_hours(working_hours):\n",
    "    try:\n",
    "        parts = working_hours.split(':')\n",
    "        weekend_parts = parts[6:7]\n",
    "        weekend_hours = sum(1 for part in weekend_parts if part.strip())\n",
    "        return weekend_hours\n",
    "    except Exception as e:\n",
    "        return 0 \n",
    "data['weekday_hours'] = data['calculated_working_hours'].apply(get_weekday_hours)\n",
    "data['weekend_hours'] = data['calculated_working_hours'].apply(get_weekend_hours)\n",
    "data['is_weekend_open'] = data['calculated_working_hours'].apply(has_values_after_colon)\n",
    "\n",
    "data['calculated_working_hours'] = data['calculated_working_hours'].apply(lambda x: re.sub(r'[^\\d:-]', '', x))\n",
    "data['weekday_hours'] = data['calculated_working_hours'].apply(get_weekday_hours)\n",
    "data['weekend_hours'] = data['calculated_working_hours'].apply(get_weekend_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular Times Classification for Each Hour Using KNN by Pramila Yadav UBIT: 50613803\n",
    "- *Analysis:* KNN categorizes popularity levels for each hour (e.g., High, Medium, Low) based on historical hourly visitation data. Scaling the features ensures fair distance computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_numeric.fillna(data_numeric.mean(), inplace=True)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\312088207.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['predicted_popularity'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "data_numeric = data[numeric_columns]\n",
    "data_numeric.fillna(data_numeric.mean(), inplace=True)\n",
    "\n",
    "def categorize_popularity(hourly_data):\n",
    "    if hourly_data > 70:\n",
    "        return 'high'\n",
    "    elif hourly_data > 40:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "    for hour in range(24):\n",
    "        column_name = f'{day}_{hour:02d}'\n",
    "        data[column_name + '_category'] = data[column_name].apply(categorize_popularity)\n",
    "X = []\n",
    "y = []\n",
    "for idx, row in data.iterrows():\n",
    "    for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "        for hour in range(24):\n",
    "            column_name = f'{day}_{hour:02d}'\n",
    "            X.append(row[[column_name]]) \n",
    "            y.append(row[column_name + '_category'])  \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "assert X.shape[0] == y.shape[0], f\"Inconsistent shapes: X has {X.shape[0]} samples, but y has {y.shape[0]} samples.\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "data['predicted_popularity'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest 5 Places for Each Place Using BallTree by Tharunnesh Ramamoorthy UBIT: 50611344\n",
    "- *Analysis:* BallTree efficiently calculates the nearest neighbors for each tourist location based on their geographical coordinates using the haversine distance metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_27712\\919310466.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['nearest_neighbors'] = get_nearest_neighbors(tree, coords, names, k=5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "coords = data[['latitude', 'longitude']].values\n",
    "names = data['name'].values\n",
    "\n",
    "tree = BallTree(np.deg2rad(coords), metric='haversine')\n",
    "\n",
    "def get_nearest_neighbors(tree, coords, names, k=5):\n",
    "    distances, indices = tree.query(np.deg2rad(coords), k=k+1) \n",
    "    \n",
    "    distances = np.rad2deg(distances) * 6371 \n",
    "    nearest_neighbors = []\n",
    "    for i, (dists, idxs) in enumerate(zip(distances, indices)):\n",
    "        neighbors = [f\"{names[idx]}:{dists[j]:.2f}km\" for j, idx in enumerate(idxs[1:], 1)] \n",
    "        nearest_neighbors.append(\", \".join(neighbors))\n",
    "    return nearest_neighbors\n",
    "\n",
    "data['nearest_neighbors'] = get_nearest_neighbors(tree, coords, names, k=5)\n",
    "data.to_csv('nearest_neighbours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>us_state</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>rating_scaled</th>\n",
       "      <th>Monday_00</th>\n",
       "      <th>Monday_01</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunday_16_category</th>\n",
       "      <th>Sunday_17_category</th>\n",
       "      <th>Sunday_18_category</th>\n",
       "      <th>Sunday_19_category</th>\n",
       "      <th>Sunday_20_category</th>\n",
       "      <th>Sunday_21_category</th>\n",
       "      <th>Sunday_22_category</th>\n",
       "      <th>Sunday_23_category</th>\n",
       "      <th>predicted_popularity</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mardis Mill Falls</td>\n",
       "      <td>34.044364</td>\n",
       "      <td>-86.571446</td>\n",
       "      <td>Blountsville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.6</td>\n",
       "      <td>High</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Easley Covered Bridge:544.56km, Horton Mill Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterville Usa/Escape House</td>\n",
       "      <td>30.258331</td>\n",
       "      <td>-87.687064</td>\n",
       "      <td>Gulf shores</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bamahenge:807.15km, Uss Alabama Battleship Mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bama Bison Rv Park &amp; Farm</td>\n",
       "      <td>32.425044</td>\n",
       "      <td>-85.250269</td>\n",
       "      <td>Opelika</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>High</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dixie Walking Trail:209.42km, Museum Of Wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Mobile Tunnel</td>\n",
       "      <td>30.690009</td>\n",
       "      <td>-88.035620</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.8</td>\n",
       "      <td>High</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooper Riverside Park:10.93km, Exploreum Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bamahenge</td>\n",
       "      <td>30.331442</td>\n",
       "      <td>-87.567232</td>\n",
       "      <td>Elberta</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterville Usa/Escape House:807.15km, Uss Alab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name   latitude  longitude          city us_state  \\\n",
       "0            Mardis Mill Falls  34.044364 -86.571446  Blountsville  Alabama   \n",
       "1  Waterville Usa/Escape House  30.258331 -87.687064   Gulf shores  Alabama   \n",
       "2    Bama Bison Rv Park & Farm  32.425044 -85.250269       Opelika  Alabama   \n",
       "3            The Mobile Tunnel  30.690009 -88.035620        Mobile  Alabama   \n",
       "4                    Bamahenge  30.331442 -87.567232       Elberta  Alabama   \n",
       "\n",
       "   rating rating_category  rating_scaled  Monday_00  Monday_01  ...  \\\n",
       "0     4.6            High            4.6          0          0  ...   \n",
       "1     4.3          Medium            4.3          0          0  ...   \n",
       "2     5.0            High            5.0          0          0  ...   \n",
       "3     4.8            High            4.8          0          0  ...   \n",
       "4     4.5          Medium            4.5          0          0  ...   \n",
       "\n",
       "   Sunday_16_category  Sunday_17_category  Sunday_18_category  \\\n",
       "0                 low                 low                 low   \n",
       "1                 low                 low                 low   \n",
       "2                 low                 low                 low   \n",
       "3                 low                 low                 low   \n",
       "4                 low                 low                 low   \n",
       "\n",
       "   Sunday_19_category  Sunday_20_category  Sunday_21_category  \\\n",
       "0                 low                 low                 low   \n",
       "1                 low                 low                 low   \n",
       "2                 low                 low                 low   \n",
       "3                 low                 low                 low   \n",
       "4                 low                 low                 low   \n",
       "\n",
       "   Sunday_22_category  Sunday_23_category  predicted_popularity  \\\n",
       "0                 low                 low                   NaN   \n",
       "1                 low                 low                   NaN   \n",
       "2                 low                 low                   NaN   \n",
       "3                 low                 low                   NaN   \n",
       "4                 low                 low                   NaN   \n",
       "\n",
       "                                   nearest_neighbors  \n",
       "0  Easley Covered Bridge:544.56km, Horton Mill Co...  \n",
       "1  Bamahenge:807.15km, Uss Alabama Battleship Mem...  \n",
       "2  Dixie Walking Trail:209.42km, Museum Of Wonder...  \n",
       "3  Cooper Riverside Park:10.93km, Exploreum Scien...  \n",
       "4  Waterville Usa/Escape House:807.15km, Uss Alab...  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Rating Classification Using Decision Tree by Hari Chandan Gooda UBIT : 50614165\n",
    "- *Analysis:* A Decision Tree Classifier categorizes locations into High, Medium, or Low rating categories based on features like location and visitation data. The simple tree structure ensures interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_final = pd.read_csv('nearest_neighbours.csv')\n",
    "\n",
    "X = df_final.drop(['rating', 'rating_category'], axis=1)\n",
    "y = df_final['rating_category']\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "clf = DecisionTreeClassifier(max_depth = 2, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "df_final['predicted_rating_category'] = clf.predict(X)\n",
    "\n",
    "# df_final.to_csv('updated_with_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df_final.drop(['rating', 'rating_category'], axis=1)\n",
    "y = df_final['rating_category']\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth = 2, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "df_final['predicted_rating_category'] = clf.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>us_state</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>rating_scaled</th>\n",
       "      <th>Monday_00</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunday_17_category</th>\n",
       "      <th>Sunday_18_category</th>\n",
       "      <th>Sunday_19_category</th>\n",
       "      <th>Sunday_20_category</th>\n",
       "      <th>Sunday_21_category</th>\n",
       "      <th>Sunday_22_category</th>\n",
       "      <th>Sunday_23_category</th>\n",
       "      <th>predicted_popularity</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>predicted_rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mardis Mill Falls</td>\n",
       "      <td>34.044364</td>\n",
       "      <td>-86.571446</td>\n",
       "      <td>Blountsville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.6</td>\n",
       "      <td>High</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Easley Covered Bridge:544.56km, Horton Mill Co...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Waterville Usa/Escape House</td>\n",
       "      <td>30.258331</td>\n",
       "      <td>-87.687064</td>\n",
       "      <td>Gulf shores</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bamahenge:807.15km, Uss Alabama Battleship Mem...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bama Bison Rv Park &amp; Farm</td>\n",
       "      <td>32.425044</td>\n",
       "      <td>-85.250269</td>\n",
       "      <td>Opelika</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>High</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dixie Walking Trail:209.42km, Museum Of Wonder...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Mobile Tunnel</td>\n",
       "      <td>30.690009</td>\n",
       "      <td>-88.035620</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.8</td>\n",
       "      <td>High</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooper Riverside Park:10.93km, Exploreum Scien...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bamahenge</td>\n",
       "      <td>30.331442</td>\n",
       "      <td>-87.567232</td>\n",
       "      <td>Elberta</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterville Usa/Escape House:807.15km, Uss Alab...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         name   latitude  longitude  \\\n",
       "0           0            Mardis Mill Falls  34.044364 -86.571446   \n",
       "1           1  Waterville Usa/Escape House  30.258331 -87.687064   \n",
       "2           2    Bama Bison Rv Park & Farm  32.425044 -85.250269   \n",
       "3           3            The Mobile Tunnel  30.690009 -88.035620   \n",
       "4           4                    Bamahenge  30.331442 -87.567232   \n",
       "\n",
       "           city us_state  rating rating_category  rating_scaled  Monday_00  \\\n",
       "0  Blountsville  Alabama     4.6            High            4.6          0   \n",
       "1   Gulf shores  Alabama     4.3          Medium            4.3          0   \n",
       "2       Opelika  Alabama     5.0            High            5.0          0   \n",
       "3        Mobile  Alabama     4.8            High            4.8          0   \n",
       "4       Elberta  Alabama     4.5          Medium            4.5          0   \n",
       "\n",
       "   ...  Sunday_17_category  Sunday_18_category  Sunday_19_category  \\\n",
       "0  ...                 low                 low                 low   \n",
       "1  ...                 low                 low                 low   \n",
       "2  ...                 low                 low                 low   \n",
       "3  ...                 low                 low                 low   \n",
       "4  ...                 low                 low                 low   \n",
       "\n",
       "   Sunday_20_category  Sunday_21_category  Sunday_22_category  \\\n",
       "0                 low                 low                 low   \n",
       "1                 low                 low                 low   \n",
       "2                 low                 low                 low   \n",
       "3                 low                 low                 low   \n",
       "4                 low                 low                 low   \n",
       "\n",
       "   Sunday_23_category  predicted_popularity  \\\n",
       "0                 low                   NaN   \n",
       "1                 low                   NaN   \n",
       "2                 low                   NaN   \n",
       "3                 low                   NaN   \n",
       "4                 low                   NaN   \n",
       "\n",
       "                                   nearest_neighbors  \\\n",
       "0  Easley Covered Bridge:544.56km, Horton Mill Co...   \n",
       "1  Bamahenge:807.15km, Uss Alabama Battleship Mem...   \n",
       "2  Dixie Walking Trail:209.42km, Museum Of Wonder...   \n",
       "3  Cooper Riverside Park:10.93km, Exploreum Scien...   \n",
       "4  Waterville Usa/Escape House:807.15km, Uss Alab...   \n",
       "\n",
       "   predicted_rating_category  \n",
       "0                       High  \n",
       "1                     Medium  \n",
       "2                       High  \n",
       "3                       High  \n",
       "4                     Medium  \n",
       "\n",
       "[5 rows x 356 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()\n",
    "# df_final.to_csv(\"Final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
